{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4403db3f",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d9377",
   "metadata": {},
   "source": [
    "### Normalization and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf330323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_robust_scale_features(df):\n",
    "    \"\"\"Scale features within each sentence group using Robust Scaler\"\"\"\n",
    "    scaled_df = df.copy()\n",
    "    \n",
    "    # Get all numeric features\n",
    "    numeric_cols = scaled_df.select_dtypes(include=[np.number]).columns\n",
    "    features = [col for col in numeric_cols \n",
    "               if col not in ['id', 'n', 'sentence', 'is_root', 'vertex', 'is_articulation']]\n",
    "\n",
    "    scaled_df[features] = scaled_df[features].astype(float)\n",
    "\n",
    "    # Group by language and sentence ID\n",
    "    for (lang, sent), group in scaled_df.groupby(['language', 'sentence']):\n",
    "        \n",
    "        # Apply RobustScaler within each sentence group\n",
    "        scaler = RobustScaler()  \n",
    "        for feature in features:\n",
    "            scaled_values = scaler.fit_transform(group[[feature]].values.reshape(-1, 1))\n",
    "            scaled_df.loc[group.index, feature] = scaled_values.flatten()\n",
    "\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ffad1",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "- Create a group id to determine language and sentence groups\n",
    "- Apply feature scaling\n",
    "- Define the features and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5541bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \"\"\"Prepare data for training\"\"\"\n",
    "    # Create a unique identifier for each sentence\n",
    "    df['sentence_id'] = df['language'] + '_' + df['sentence'].astype(str)\n",
    "    \n",
    "    # Scale features within each sentence\n",
    "    df_scaled = sentence_robust_scale_features(df)\n",
    "    \n",
    "    feature_list = [col for col in df_scaled.columns \n",
    "               if col not in ['id', 'n', 'sentence', 'is_root', 'vertex', 'language', 'sentence_id']\n",
    "               and df_scaled[col].dtype in [np.float64, np.int64]]\n",
    "    \n",
    "    print(f\"Using features: {feature_list}\")\n",
    "    \n",
    "    X = df_scaled[feature_list]\n",
    "    \n",
    "    # Only extract y if is_root exists in the dataframe\n",
    "    if 'is_root' in df_scaled.columns:\n",
    "        y = df_scaled['is_root']\n",
    "    else:\n",
    "        y = None\n",
    "        \n",
    "    groups = df_scaled['sentence_id']\n",
    "    \n",
    "    return X, y, groups, df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143f3fdc",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_root_classifier(train_data):\n",
    "    \"\"\"Train a classifier for root node detection\"\"\"\n",
    "    X, y, groups, _ = prepare_data(train_data)\n",
    "    \n",
    "    # Set up GroupKFold to ensure sentences stay together\n",
    "    group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "    clf = BalancedRandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        sampling_strategy='auto',\n",
    "        class_weight='balanced',\n",
    "        replacement=True, \n",
    "        bootstrap=False   \n",
    "    )\n",
    "    \n",
    "    # Initialize balanced classifier to handle class imbalance\n",
    "    # clf = BalancedRandomForestClassifier(\n",
    "    #     n_estimators=200,         \n",
    "    #     max_depth=None,            \n",
    "    #     max_features='sqrt',      \n",
    "    #     sampling_strategy='auto', \n",
    "    #     replacement=True,         \n",
    "    #     bootstrap=False,           \n",
    "    #     random_state=42,\n",
    "    #     n_jobs=-1                 \n",
    "    # )\n",
    "    \n",
    "    # Perform cross-validation, ensuring sentences stay together\n",
    "    for fold, (train_idx, val_idx) in enumerate(group_kfold.split(X, y, groups)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        y_proba = clf.predict_proba(X_val)\n",
    "\n",
    "        print(f\"\\nFold {fold+1} Metrics:\")\n",
    "        print(classification_report(y_val, y_pred, digits=4))\n",
    "        print(f\"AUC-ROC: {roc_auc_score(y_val, y_proba[:, 1]):.4f}\")\n",
    "    \n",
    "    # Train final model on all data\n",
    "    final_clf = BalancedRandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        sampling_strategy='auto',\n",
    "        class_weight='balanced',\n",
    "        replacement=True, \n",
    "        bootstrap=False   \n",
    "    )\n",
    "\n",
    "    # final_clf = BalancedRandomForestClassifier(\n",
    "    #     n_estimators=200,         \n",
    "    #     max_depth=None,                 \n",
    "    #     max_features='sqrt',      \n",
    "    #     sampling_strategy='auto', \n",
    "    #     replacement=True,         \n",
    "    #     bootstrap=False,           \n",
    "    #     random_state=42,\n",
    "    #     n_jobs=-1                 \n",
    "    # )\n",
    "\n",
    "    final_clf.fit(X, y)\n",
    "        \n",
    "    # Feature importance\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': final_clf.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Feature Importances:\")\n",
    "    print(feature_importances.head(10))\n",
    "    \n",
    "    return final_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d270e1",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_roots(classifier, test_data):\n",
    "    \"\"\"Make predictions on test data\"\"\"\n",
    "    X_test, y_test, _, normalized_test = prepare_data(test_data)\n",
    "    \n",
    "    # Get probability predictions\n",
    "    return classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9fe72a",
   "metadata": {},
   "source": [
    "### Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file(predictions_df, original_test_data, output_path='submission.csv'):\n",
    "    \"\"\"Generate the final submission file in the required format\"\"\"\n",
    "    # Create a mapping from (language, sentence) to original ID\n",
    "    sentence_lang_to_id = {}\n",
    "    \n",
    "    # Create mapping from (language, sentence) to id\n",
    "    for _, row in original_test_data.drop_duplicates(['language', 'sentence']).iterrows():\n",
    "        sentence_lang_to_id[(row['language'], row['sentence'])] = row['id']\n",
    "    \n",
    "    # Extract sentence IDs and predicted root vertices\n",
    "    submission = []\n",
    "    \n",
    "    for (lang, sent), group in predictions_df.groupby(['language', 'sentence']):\n",
    "        # Get the node with highest probability for this sentence and language\n",
    "        top_node = group.sort_values('root_probability', ascending=False).iloc[0]\n",
    "        \n",
    "        # Use the original id\n",
    "        original_id = sentence_lang_to_id.get((lang, sent))\n",
    "        \n",
    "        submission.append({\n",
    "            'id': original_id,\n",
    "            'root': int(top_node['vertex'])\n",
    "        })\n",
    "    \n",
    "    # Create and sort submission dataframe\n",
    "    submission_df = pd.DataFrame(submission)\n",
    "    submission_df = submission_df.sort_values('id')\n",
    "    \n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    print(f\"Submission saved to {output_path}\")\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00565139",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189987fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "train_data = pd.read_csv('../data/train_processed.csv')\n",
    "test_data = pd.read_csv('../data/test_processed.csv')\n",
    "\n",
    "print(\"Training root node classifier...\")\n",
    "classifier = train_root_classifier(train_data)\n",
    "    \n",
    "print(\"\\nGenerating predictions...\")\n",
    "test_data['root_probability'] = predict_roots(classifier, test_data)\n",
    "    \n",
    "print(\"\\nCreating submission file...\")\n",
    "submission = generate_submission_file(predictions, test_data, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
